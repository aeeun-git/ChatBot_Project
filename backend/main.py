
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import openai
import os
from dotenv import load_dotenv
from google.cloud import language_v2
from sentence_transformers import SentenceTransformer, util

# â–¶ í™˜ê²½ ì„¤ì •
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = r"C:\Path\chatbot-454403-a78c4d9ba772.json"
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("âŒ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

client = openai.OpenAI(api_key=OPENAI_API_KEY)

# â–¶ FastAPI ì´ˆê¸°í™”
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

chat_history = []

# â–¶ ê°ì •ë¶„ì„ ê²°ê³¼ ëª¨ë¸
class SentenceSentiment(BaseModel):
    text: str
    score: float
    magnitude: float

class SentimentData(BaseModel):
    document_score: float
    document_magnitude: float
    language: str
    sentences: list[SentenceSentiment]

# â–¶ ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ChatRequest(BaseModel):
    user_input: str

class ChatResponse(BaseModel):
    response: str
    sentiment: SentimentData | None
    action: dict | None

# â–¶ ê°ì • ë¶„ì„
def analyze_sentiment(text: str) -> SentimentData:
    client_nlp = language_v2.LanguageServiceClient()
    document = {"content": text, "type_": language_v2.Document.Type.PLAIN_TEXT}

    response = client_nlp.analyze_sentiment(request={"document": document, "encoding_type": language_v2.EncodingType.UTF8})

    sentences = [
        SentenceSentiment(
            text=s.text.content,
            score=s.sentiment.score,
            magnitude=s.sentiment.magnitude,
        ) for s in response.sentences
    ]

    return SentimentData(
        document_score=response.document_sentiment.score,
        document_magnitude=response.document_sentiment.magnitude,
        language=response.language_code,
        sentences=sentences,
    )

# â–¶ í–‰ë™ ì •ì˜ ë° ë¶„ë¥˜
embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

action_candidates = {
    "wave_hand": ["ì•ˆë…•", "í•˜ì´", "ë°˜ê°€ì›Œìš”", "ì¢‹ì€ í•˜ë£¨ ë³´ë‚´"],
    "bow": ["ê³ ë§ˆì›Œ", "ê°ì‚¬í•´ìš”", "ì •ë§ ê³ ë§™ìŠµë‹ˆë‹¤"],
    "wave_goodbye": ["ì˜ ê°€", "ë˜ ë´", "ì´ë§Œ ê°€ë³¼ê²Œ"]
}

action_type_to_category = {
    "wave_hand": "ì¸ì‚¬",
    "bow": "ê°ì‚¬",
    "wave_goodbye": "ì‘ë³„"
}

def detect_action(text: str):
    input_embedding = embedding_model.encode(text, convert_to_tensor=True)
    best_action, best_score = None, 0.0

    for action, phrases in action_candidates.items():
        phrase_embeddings = embedding_model.encode(phrases, convert_to_tensor=True)
        score = util.pytorch_cos_sim(input_embedding, phrase_embeddings).max().item()
        if score > best_score:
            best_score = score
            best_action = action

    return best_action, best_score

def determine_intensity(score: float, magnitude: float) -> str:
    if abs(score) >= 0.5 or magnitude >= 2.0:
        return "strong"
    elif abs(score) >= 0.2 or magnitude >= 1.0:
        return "normal"
    else:
        return "weak"

# â–¶ /chat ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(request: ChatRequest):
    user_input = request.user_input
    print(f"ğŸ‘¤ ì…ë ¥: {user_input}")

    try:
        sentiment_result = analyze_sentiment(user_input)
    except Exception as e:
        print(f"âš ï¸ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
        sentiment_result = None

    messages = [
        {"role": "system", "content": "ê·€ì—½ê³  ê¹ì°í•œ ìºë¦­í„°ì•¼, ìœ ì¾Œí•˜ê³  ì¬ë¯¸ìˆê²Œ ëŒ€í™”í•´ì¤˜"},
        *chat_history,
        {"role": "user", "content": user_input}
    ]

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.7
        )
        ai_response = response.choices[0].message.content
        print(f"ğŸ¤– GPT ì‘ë‹µ: {ai_response}")
    except Exception as e:
        print(f"âŒ OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"response": "OpenAI API í˜¸ì¶œ ì˜¤ë¥˜", "sentiment": sentiment_result, "action": None}

    # ëŒ€í™” ê¸°ë¡ ì €ì¥
    chat_history.append({"role": "user", "content": user_input})
    chat_history.append({"role": "assistant", "content": ai_response})

    # â–¶ í–‰ë™ íŒë‹¨
    action_type, similarity = detect_action(user_input)
    intensity = determine_intensity(sentiment_result.document_score, sentiment_result.document_magnitude) if sentiment_result else "normal"
    category = action_type_to_category.get(action_type, "ê¸°íƒ€")

    return {
        "response": ai_response,
        "sentiment": sentiment_result,
        "action": {
            "type": action_type,
            "category": category,
            "intensity": intensity,
            "similarity_score": similarity
        }
    }